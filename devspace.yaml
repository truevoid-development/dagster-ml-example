version: v2beta1
name: devspace-iceberg
pipelines:
  dev:
    run: |-
      build_images --all -t ${DEVSPACE_RANDOM}
      create_deployments minio nessie trino python
      start_dev --all

images:
  hive-metastore:
    image: truevoid/hive-metastore
    dockerfile: hive-metastore/Dockerfile
    context: hive-metastore

  python:
    image: truevoid/python
    dockerfile: python-hdfs/Dockerfile
    context: python-hdfs

deployments:
  postgres:
    helm:
      chart:
        name: postgresql
        repo: https://charts.bitnami.com/bitnami
      values:
        global:
          postgresql:
            auth:
              postgresPassword: hive
              username: hive
              password: hive
              database: hive
        primary:
          livenessProbe:
            enabled: false
          resourcePreset: medium
          persistence:
            enabled: false
          nodeSelector: &node_selector
            kubernetes.io/hostname: node-dedicated-0

  hive-metastore:
    helm:
      values:
        nodeSelector: *node_selector
        containers:
        - image: truevoid/hive-metastore:${DEVSPACE_RANDOM}
          name: hive-metastore
          env:
          - name: SERVICE_NAME
            value: metastore
          - name: DB_DRIVER
            value: postgres
          - name: SERVICE_OPTS
            value: >-
              -Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver
              -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://postgres-postgresql-hl:5432/hive
              -Djavax.jdo.option.ConnectionUserName=hive
              -Djavax.jdo.option.ConnectionPassword=hive
        service:
          name: hive-metastore
          ports:
          - containerPort: 9083
            port: 9083

  minio:
    helm:
      chart:
        name: minio
        repo: https://charts.bitnami.com/bitnami
      values:
        provisioning:
          nodeSelector: *node_selector
        auth:
          rootPassword: miniopass
        defaultBuckets: storage
        persistence:
          enabled: true
        pdb:
          create: false

  nessie:
    helm:
      chart:
        path: charts/nessie

  datanode:
    helm:
      values:
        nodeSelector: *node_selector
        containers:
        - image: docker.io/apache/hadoop:3
          name: datanode
          command: [/opt/starter.sh, hdfs, datanode]
          env:
          - name: ENSURE_NAMENODE_DIR
            value: /tmp/hadoop-hadoop/dfs/name
          - name: CORE-SITE.XML_fs.default.name
            value: hdfs://namenode
          - name: CORE-SITE.XML_fs.defaultFS
            value: hdfs://namenode
          - name: CORE-SITE.XML_dfs.permissions
            value: "false"
          - name: CORE-SITE.XML_dfs.namenode.rpc-address
            value: namenode:8020
          - name: CORE-SITE.XML_dfs.replication
            value: "1"
        service:
          name: datanode
          clusterIP: None
          ports:
          - containerPort: 9864
            port: 9864

  namenode:
    helm:
      values:
        nodeSelector: *node_selector
        containers:
        - image: docker.io/apache/hadoop:3
          name: namenode
          command: [/opt/starter.sh, hdfs, namenode]
          env:
          - name: ENSURE_NAMENODE_DIR
            value: /tmp/hadoop-hadoop/dfs/name
          - name: CORE-SITE.XML_fs.default.name
            value: hdfs://namenode
          - name: CORE-SITE.XML_fs.defaultFS
            value: hdfs://namenode
          - name: CORE-SITE.XML_dfs.permissions
            value: "false"
          - name: CORE-SITE.XML_dfs.namenode.rpc-address
            value: 0.0.0.0:8020
          - name: CORE-SITE.XML_dfs.replication
            value: "1"
        service:
          name: namenode
          clusterIP: None
          ports:
          - containerPort: 9870
            port: 9870
          - containerPort: 8020
            port: 8020

  spark:
    helm:
      chart:
        name: spark
        repo: https://charts.bitnami.com/bitnami
      values:
        master: &spark_config
          nodeSelector: *node_selector
        worker: *spark_config

  trino:
    helm:
      chart:
        name: trino
        repo: https://trinodb.github.io/charts/
      values:
        image:
          tag: "452"
        additionalConfigProperties:
        - http-server.process-forwarded=true
        coordinator: &trino_config
          nodeSelector: *node_selector
          additionalNodeProperties:
          - HADOOP_USER_NAME=hadoop
        worker: *trino_config
        additionalCatalogs:
          iceberg-hive: |-
            connector.name=iceberg
            iceberg.catalog.type=hive_metastore
            hive.metastore.uri=thrift://hive-metastore:9083
            fs.hadoop.enabled=true
          iceberg: |-
            connector.name=iceberg
            iceberg.catalog.type=rest
            iceberg.rest-catalog.uri=http://nessie:19120/iceberg
            iceberg.rest-catalog.prefix=${DEVSPACE_NAMESPACE}
            iceberg.rest-catalog.location=s3://storage/
            fs.native-s3.enabled=true
            s3.endpoint=http://minio:9000
            s3.region=euwest
            s3.aws-access-key=admin
            s3.aws-secret-key=miniopass
            s3.path-style-access=true

  python:
    helm:
      values:
        nodeSelector: *node_selector
        containers:
        - image: truevoid/python
          name: python
          command: [sleep, infinity]
        service:
          name: pyspark
          clusterIP: None
          ports:
          - containerPort: 10000
            port: 10000

dev:
  python:
    labelSelector:
      app.kubernetes.io/component: python
    sync:
    - path: python-hdfs:.
      excludePaths:
      - "*"
      - "!main.py"

  trino:
    labelSelector:
      app.kubernetes.io/instance: trino
      app.kubernetes.io/component: coordinator
    ports:
    - port: "8080"

  nessie:
    labelSelector:
      app.kubernetes.io/instance: nessie
      app.kubernetes.io/name: nessie
    ports:
    - port: "19120"

  minio:
    labelSelector:
      app.kubernetes.io/instance: minio
      app.kubernetes.io/name: minio
    ports:
    - port: "9001"

commands:
  initialzie: |-
    devspace enter -c python -- bash -c "HADOOP_USER_NAME=hadoop hdfs dfs -chown -R 777 /"

  nessie-cli: |-
    kubectl run -it --rm \
      --image=ghcr.io/projectnessie/nessie-cli:latest nessie-cli -- \
        --uri=http://nessie:19120/api/v2

  trino: |-
    kubectl run -it --rm \
      --image=trinodb/trino:latest trino-cli -- \
        trino http://admin@trino:8080 --catalog iceberg

  python: |-
    devspace enter -c python -- bash -c ". /root/.bashrc && poetry run python main.py"

  dump: |-
    kubectl exec postgres-postgresql-0 -- \
      bash -c "PGPASSWORD=hive pg_dump -Z9 -v -h localhost -U hive -d hive" \
      > $(date +'%s').tar.gz

  restore: |-
    helm uninstall --ignore-not-found hive-metastore

    kubectl exec postgres-postgresql-0 -- \
      bash -c "PGPASSWORD=hive dropdb -h localhost -U hive hive"

    kubectl exec postgres-postgresql-0 -- \
      bash -c "PGPASSWORD=hive createdb -h localhost -U hive hive"

    kubectl exec -i postgres-postgresql-0 -- \
      bash -c "PGPASSWORD=hive pg_restore --clean --if-exists -h localhost -d hive -U hive" \
      <$@

    devspace deploy --skip-build hive-metastore
